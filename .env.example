# Uncomment any of the following to run a test locally on those data sources.
# postgres is the default so that's used if all these below are commented.
# test_data_source=postgres
# test_data_source=snowflake
# test_data_source=bigquery
# test_data_source=redshift
# test_data_source=athena
# test_data_source=spark
# test_data_source=spark_df

# This flag allows to skip the optimized local behavior and run on postgres with a clean schema, just like on CI.
# By default running the test suite on your own dev machine will skip dropping the schema and test tables will be
# reused when running them next time. Of course, if the data in the test tables change, the test tables will be
# recreated.
# POSTGRES_REUSE_SCHEMA=DISABLED

BIGQUERY_ACCOUNT_INFO_JSON_PATH=/Users/you/.soda/my_bigquery_account_info.json
BIGQUERY_DATASET=test

SNOWFLAKE_HOST=https://sodadatapartner.eu-central-1.snowflakecomputing.com/
SNOWFLAKE_ACCOUNT=SODADATAPARTNER.eu-central-1
SNOWFLAKE_USERNAME=***
SNOWFLAKE_PASSWORD=***
SNOWFLAKE_DATABASE=CATALOG_INTEGRATION_DEMO
SNOWFLAKE_SCHEMA=public

REDSHIFT_HOST=soda-test.c0l8nhpcaknw.eu-west-1.redshift.amazonaws.com
REDSHIFT_USERNAME=soda
REDSHIFT_PASSWORD=***
REDSHIFT_DATABASE=***
REDSHIFT_PORT=5439

# MilanLukac admin - VERY TEMPORARY will be changed ASAP
# Access this account through Soda Sandbox in Okta
ATHENA_ACCESS_KEY_ID=***
ATHENA_SECRET_ACCESS_KEY=***
ATHENA_STAGING_DIR=s3://soda-athena-test/staging-dir
ATHENA_DATA_DIR=s3://soda-athena-test/data
ATHENA_SCHEMA=test

# Flag to skip scientific tests if installation doesn't work on your machine
# SCIENTIFIC_TESTS="SKIP"

# Creds for dev.sodadata.io if you want to use the manual integration tests in soda/core/tests/integration
DEV_SODADATA_IO_API_KEY_ID=***
DEV_SODADATA_IO_API_KEY_SECRET=***
